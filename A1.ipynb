{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Can Food Models have Bias? \n",
    "### _A rigorous evaluation of the impact of data on model performance_\n",
    "\n",
    "Model performance can vary significantly with different groups or types of data, especially if a model has high bias. Models have bias in part because training data has bias, and training data has bias because people curate training data. A prerequisite to evaluating model bias is understanding how your model performs on different types of data. To achieve a comprehensive understanding of model performance, you can use established evaluation metrics. In this module, you will learn what those metrics are, how they work, and how to interpret them. \n",
    "\n",
    "\n",
    "<img src=\"model_bias.png\" alt=\"drawing\" width=\"450\" height=\"450\"/>\n",
    "\n",
    "This module will take place over the course of 3 in-class periods and an assignment. The schedule for the module is as follows: \n",
    "\n",
    "## Module Schedule\n",
    "\n",
    "### Day 1: Intro to the Blackbox\n",
    "\n",
    "#### _Agenda:_\n",
    "\n",
    "* Discussion: impacts of machine learning (15 min)\n",
    "* Lecture: The life cycle of an ML model (15 min)\n",
    "* In-class activity: Playing with input data (40 min)\n",
    "* Reflection (15 min)\n",
    "* Brief course overview and assignment intro (10 min)\n",
    "* Fill out course entrance survey and ask remaining questions (5 min)\n",
    "\n",
    "#### _Homework:_ \n",
    "\n",
    "* Read [this](https://www.datacamp.com/blog/machine-learning-lifecycle-explained) article on the ML model development cycle\n",
    "\n",
    "### Day 2: Model Evaluation\n",
    "\n",
    "#### _Agenda:_\n",
    "\n",
    "* Discussion: Debriefing the homework reading (10 min)\n",
    "* Lecture: Evaluation Metrics (20 min)\n",
    "* In-class activity: Interpreting metrics practice (40 min)\n",
    "* Reflection (5 min)\n",
    "* Work time: Assignment 1 (25 min)\n",
    "\n",
    "#### _Homework:_ \n",
    "\n",
    "* Finish through section x of assignment 1 (in this notebook!)\n",
    "* Read [this](https://spotintelligence.com/2023/04/07/data-quality-machine-learning/) article on evaluating data quality\n",
    "\n",
    "### Day 3: Dataset Evaluation\n",
    "\n",
    "#### _Agenda:_\n",
    "\n",
    "* Discussion: How might you use evaluation metrics to assess bias? (15 min)\n",
    "* Lecture: \n",
    "    - Dataset splitting (10 min)\n",
    "    - In dataset vs. out of dataset evaluation (10 min)\n",
    "* In class activity: Playing with datasets and dataset splitting (40 min)\n",
    "* Reflection (5 min)\n",
    "* Work time: Assignment 1 (20 min)\n",
    "\n",
    "### _Homework:_ \n",
    "\n",
    "* Finish assignment 1\n",
    "\n",
    "# Assignment 1: \n",
    "\n",
    "## Metrics Overview\n",
    "\n",
    "The metrics we will implement in this assignment are:\n",
    "\n",
    "* Confusion Matrix \n",
    "* Classification Accuracy\n",
    "* Precision \n",
    "* Recall\n",
    "\n",
    "_Consult [this article](https://arxiv.org/abs/2008.05756) to learn about the metrics and inform your implementation_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'fig'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/jess/ai_society/A1.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jess/ai_society/A1.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\u001b[39m#Fit the model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jess/ai_society/A1.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m logreg \u001b[39m=\u001b[39m LogisticRegression(C\u001b[39m=\u001b[39m\u001b[39m1e5\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jess/ai_society/A1.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m logreg\u001b[39m.\u001b[39mfig(X,y)\u001b[39m#Generate predictions with the model using our X values\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jess/ai_society/A1.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m y_pred \u001b[39m=\u001b[39m logreg\u001b[39m.\u001b[39mpredict(X)\u001b[39m#Get the confusion matrix\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jess/ai_society/A1.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m cf_matrix \u001b[39m=\u001b[39m confusion_matrix(y, y_pred)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'fig'"
     ]
    }
   ],
   "source": [
    "## Because of how graphical the confusion matrix is, we will implement most of it for you: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Accuracy\n",
    "First, read [this article](https://www.sharpsightlabs.com/blog/classification-accuracy-explained/) about classification accuracy for a brief intro. \n",
    "\n",
    "In other words, \"classification accuracy is the ratio of the number of correct predictions to the total number of input samples\" (Yalug, et al.) ([Source](https://www.sciencedirect.com/science/article/abs/pii/B9780128228289000058))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
